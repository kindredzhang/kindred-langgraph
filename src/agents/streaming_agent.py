from typing import Annotated, Sequence, TypedDict, Generator, Dict, Any
import asyncio
from dotenv import load_dotenv
from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from langgraph.graph.message import add_messages
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from pydantic import SecretStr
import os

from .models import StreamMessage, MessageType, ConversationSession, ToolCall, ToolResult
from .storage import StreamingStorage, SimpleFileStorage

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")

if not OPENAI_API_KEY:
    raise ValueError("Please set OPENAI_API_KEY in your environment variables.")


class StreamingAgentState(TypedDict):
    """æµå¼AgentçŠ¶æ€"""
    messages: Annotated[Sequence[BaseMessage], add_messages]
    session: ConversationSession
    current_step: str


# å®šä¹‰å·¥å…·
@tool
def add_numbers(a: int, b: int) -> int:
    """Add two numbers together."""
    return a + b


@tool
def multiply_numbers(a: int, b: int) -> int:
    """Multiply two numbers together."""
    return a * b


@tool
def divide_numbers(a: int, b: int) -> float:
    """Divide two numbers. Returns error if division by zero."""
    if b == 0:
        raise ValueError("Cannot divide by zero!")
    return a / b


class StreamingReActAgent:
    """æ”¯æŒçœŸæ­£æµå¼å“åº”çš„ReAct Agent"""
    
    def __init__(self, storage_dir: str = "data"):
        self.storage = StreamingStorage(SimpleFileStorage(storage_dir))
        self.tools = [add_numbers, multiply_numbers, divide_numbers]
        self.model = ChatOpenAI(
            api_key=SecretStr(OPENAI_API_KEY),
            base_url=OPENAI_BASE_URL,
            model="gpt-4o-mini",
            temperature=0.7,
            streaming=True  # å¯ç”¨æµå¼å“åº”
        ).bind_tools(self.tools)
        
        self.graph = self._build_graph()
        self.app = self.graph.compile()
    
    def _build_graph(self) -> StateGraph:
        """æ„å»ºLangGraphçŠ¶æ€å›¾"""
        graph = StateGraph(StreamingAgentState)
        
        # æ·»åŠ èŠ‚ç‚¹
        graph.add_node("thinking", self._thinking_node)
        graph.add_node("reasoning", self._reasoning_node) 
        graph.add_node("tool_calling", self._tool_calling_node)
        graph.add_node("tool_execution", ToolNode(self.tools))
        graph.add_node("final_answer", self._final_answer_node)
        
        # è®¾ç½®å…¥å£ç‚¹
        graph.set_entry_point("thinking")
        
        # æ·»åŠ è¾¹
        graph.add_edge("thinking", "reasoning")
        graph.add_conditional_edges(
            "reasoning",
            self._should_use_tools,
            {
                "use_tools": "tool_calling",
                "final_answer": "final_answer"
            }
        )
        graph.add_edge("tool_calling", "tool_execution")
        graph.add_edge("tool_execution", "reasoning")
        graph.add_edge("final_answer", END)
        
        return graph
    
    def _thinking_node(self, state: StreamingAgentState) -> StreamingAgentState:
        """æ€è€ƒèŠ‚ç‚¹ - åˆ†æç”¨æˆ·é—®é¢˜"""
        session = state["session"]
        
        thinking_msg = StreamMessage(
            type=MessageType.THINKING,
            content="ğŸ¤” è®©æˆ‘åˆ†æä¸€ä¸‹ä½ çš„é—®é¢˜...",
            metadata={"step": "initial_thinking"}
        )
        
        self.storage.add_stream_message(session, thinking_msg)
        
        return {
            "messages": state["messages"],
            "session": session,
            "current_step": "thinking"
        }
    
    def _reasoning_node(self, state: StreamingAgentState) -> StreamingAgentState:
        """æ¨ç†èŠ‚ç‚¹ - è°ƒç”¨LLMè¿›è¡Œæ¨ç†"""
        session = state["session"]
        
        reasoning_msg = StreamMessage(
            type=MessageType.REASONING,
            content="ğŸ’­ æ­£åœ¨æ¨ç†å’Œåˆ†æ...",
            metadata={"step": "reasoning"}
        )
        self.storage.add_stream_message(session, reasoning_msg)
        
        # æ„å»ºç³»ç»Ÿæç¤º
        system_message = SystemMessage(
            content="""ä½ æ˜¯ä¸€ä¸ªhelpfulçš„æ•°å­¦åŠ©æ‰‹ã€‚ä½ å¯ä»¥ä½¿ç”¨æä¾›çš„å·¥å…·æ¥è¿›è¡Œè®¡ç®—ã€‚

å½“ç”¨æˆ·æå‡ºé—®é¢˜æ—¶ï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ€è€ƒï¼š
1. ç†è§£ç”¨æˆ·çš„é—®é¢˜
2. åˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·
3. å¦‚æœéœ€è¦ï¼Œé€‰æ‹©åˆé€‚çš„å·¥å…·å¹¶è¯´æ˜åŸå› 
4. æ‰§è¡Œè®¡ç®—
5. ç»™å‡ºæœ€ç»ˆç­”æ¡ˆ

è¯·å§‹ç»ˆç”¨ä¸­æ–‡å›å¤ï¼Œå¹¶è§£é‡Šä½ çš„æ€è€ƒè¿‡ç¨‹ã€‚"""
        )
        
        # è°ƒç”¨LLM
        call_messages = [system_message] + list(state["messages"])
        response = self.model.invoke(call_messages)
        
        # æ›´æ–°æ¨ç†å†…å®¹
        content = response.content if isinstance(response.content, str) else str(response.content or "")
        reasoning_update = StreamMessage(
            type=MessageType.REASONING,
            content=f"ğŸ’­ æ¨ç†ç»“æœ: {content}",
            metadata={
                "step": "reasoning_complete",
                "has_tool_calls": bool(getattr(response, "tool_calls", None))
            }
        )
        self.storage.add_stream_message(session, reasoning_update)
        
        return {
            "messages": [response],
            "session": session,
            "current_step": "reasoning"
        }
    
    def _tool_calling_node(self, state: StreamingAgentState) -> StreamingAgentState:
        """å·¥å…·è°ƒç”¨èŠ‚ç‚¹ - å‡†å¤‡å·¥å…·è°ƒç”¨"""
        session = state["session"]
        last_message = state["messages"][-1]
        
        if hasattr(last_message, "tool_calls") and getattr(last_message, "tool_calls", None):
            for tool_call in getattr(last_message, "tool_calls", []):
                tool_msg = StreamMessage(
                    type=MessageType.TOOL_CALL,
                    content=f"ğŸ”§ å‡†å¤‡è°ƒç”¨å·¥å…·: {tool_call['name']}",
                    metadata={
                        "tool_name": tool_call["name"],
                        "tool_args": tool_call["args"],
                        "tool_id": tool_call.get("id", "")
                    }
                )
                self.storage.add_stream_message(session, tool_msg)
        
        return {
            "messages": state["messages"],
            "session": session,
            "current_step": "tool_calling"
        }
    
    def _final_answer_node(self, state: StreamingAgentState) -> StreamingAgentState:
        """æœ€ç»ˆç­”æ¡ˆèŠ‚ç‚¹"""
        session = state["session"]
        last_message = state["messages"][-1]
        
        content = last_message.content if isinstance(last_message.content, str) else str(last_message.content or "")
        
        final_msg = StreamMessage(
            type=MessageType.FINAL_ANSWER,
            content=f"âœ… æœ€ç»ˆç­”æ¡ˆ: {content}",
            metadata={"step": "completed"}
        )
        self.storage.add_stream_message(session, final_msg)
        
        # æ›´æ–°ä¼šè¯çŠ¶æ€
        self.storage.storage.update_session_status(session.session_id, "completed")
        
        return {
            "messages": state["messages"],
            "session": session,
            "current_step": "completed"
        }
    
    def _should_use_tools(self, state: StreamingAgentState) -> str:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·"""
        last_message = state["messages"][-1]
        if hasattr(last_message, "tool_calls") and getattr(last_message, "tool_calls", None):
            return "use_tools"
        return "final_answer"
    
    def stream_process(self, question: str) -> Generator[StreamMessage, None, ConversationSession]:
        """æµå¼å¤„ç†ç”¨æˆ·é—®é¢˜"""
        # åˆ›å»ºä¼šè¯
        session = self.storage.create_session(question)
        
        # æ„å»ºåˆå§‹çŠ¶æ€
        initial_state = StreamingAgentState(
            messages=[HumanMessage(content=question)],
            session=session,
            current_step="start"
        )
        
        try:
            # è¿è¡Œå›¾å¹¶æµå¼è¿”å›æ¶ˆæ¯
            for state in self.app.stream(initial_state, stream_mode="values"):
                current_session = state["session"]
                
                # è·å–æœ€æ–°æ¶ˆæ¯å¹¶æµå¼è¿”å›
                if current_session.messages:
                    latest_messages = current_session.messages[-1:]  # åªè¿”å›æœ€æ–°æ¶ˆæ¯
                    for msg in latest_messages:
                        yield msg
                
                # æ¨¡æ‹Ÿå®æ—¶å¤„ç†å»¶è¿Ÿ
                import time
                time.sleep(0.5)
            
            return session
            
        except Exception as e:
            # é”™è¯¯å¤„ç†
            error_msg = StreamMessage(
                type=MessageType.ERROR,
                content=f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}",
                metadata={"error_type": type(e).__name__}
            )
            self.storage.add_stream_message(session, error_msg)
            self.storage.storage.update_session_status(session.session_id, "error")
            yield error_msg
            return session
    
    def get_session_messages(self, session_id: str) -> list:
        """è·å–ä¼šè¯çš„æ‰€æœ‰æ¶ˆæ¯"""
        session = self.storage.storage.get_session(session_id)
        return session.messages if session else []